{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "k2i4wdcgd34tx23lrdc7",
   "authorId": "308287954429",
   "authorName": "ADMIN",
   "authorEmail": "prabhath.nanisetty@snowflake.com",
   "sessionId": "9695ca7a-dd5c-4dd3-aa8f-125b69406d1c",
   "lastEditTime": 1755039135958
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8018a5f-8d95-42cb-87f4-5057596ead01",
   "metadata": {
    "collapsed": false,
    "name": "cell12"
   },
   "source": "# Shelf AI using Cortex and Meta SegmentAnything\nThis notebook covers how to use Meta's Segment Anything model to identify various objects on a store shelf and extract that portion for Cortex.\n\n### What has been done:\n* Create image segments via masked images\n* Run Cortex Complete on each masked image to identify the product\n\n### What is still incomplete (TODO):\n* ~Cropping masked images (S)~\n* Better prompting to throw out any non-product images (i.e. ceiling, shelves) (S)\n* ~Map the masks back to the X-Y coordinates on the shelf (M)~\n* Associate prices/shelf labels to the products (L)\n* Handling multiple facings (L)\n* ~Handling products that are broken across multiple images (L)~ Partially handled\n\n### Questions left to answer:\n* Could Cortex complete just do all this without having to segment, mask, and evaluate?\n* How to associate prices/shelf tags with the corresponding product"
  },
  {
   "cell_type": "markdown",
   "id": "46859754-dafa-4c25-a3e3-4b5f329758de",
   "metadata": {
    "collapsed": false,
    "name": "cell13"
   },
   "source": "## 1. Package Imports and Model download\n\n1. You will need to set up external access integrations for the following sites `github.com` , `dl.fbaipublicfiles.com`, and PyPi for package installs. Code is in the `setup.sql` file that accompanies this notebook\n    \n2. You will also need to upload a shelf image to the notebook directory using the file browser on the left side - update any paths in this section below as well."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af44859-e7fd-4055-a079-800346e0669f",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": "import os\n\n# Key Variables that need to be modified for demoing\nSHELF_IMAGE_PATH = 'images/IMG_0741.JPG'\nMASKED_IMAGES_OUTPUT_PATH = os.getcwd() + '/outputs/'\nIMAGE_STAGE_LOCATION = '@notebook_demo_db.shelf_image_ai.image_upload_2'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "# Install Segment Anything\n",
    "# -- SegmentAnything v1.0\n",
    "!pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "\n",
    "!pip install opencv-python\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import sys\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from snowflake.cortex import complete\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9e335-396f-40c7-9420-dd17b50c810a",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "# Download the Meta SegmentAnything model - will save to local tmp directory in Container\n",
    "!wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266700d-d426-4030-863c-8dede9cdf17a",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "# FUNCTION DEFINITIONS\n\ndef show_annotations(anns):\n    \"\"\" Adds the masks back into the shelf image as annotations. Code taken from\n    the SegmentAnything v1.0 tutorial    \n    \"\"\"\n    if len(anns) == 0:\n        return\n    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n    ax = plt.gca()\n    ax.set_autoscale_on(False)\n\n    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n    img[:,:,3] = 0\n    for ann in sorted_anns:\n        m = ann['segmentation']\n        color_mask = np.concatenate([np.random.random(3), [0.7]])\n        img[m] = color_mask\n    ax.imshow(img)\n\ndef crop_image_to_relevant(img, mask_array):\n    \"\"\" Auto crop the masked image without all the surrounding mask\"\"\"\n    \n    # Convert mask to binary if not already\n    binary_mask = (mask_array > 0).astype(np.uint8) * 255\n    \n    # Find contours in the mask\n    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    \n    if len(contours) == 0:\n        return img  # Return original if no contours found\n    \n    # Get the largest contour (main product)\n    largest_contour = max(contours, key=cv2.contourArea)\n    \n    # Get bounding box coordinates\n    x, y, w, h = cv2.boundingRect(largest_contour)\n    \n    # Add small padding to ensure we don't cut off edges\n    padding = 10\n    x = max(0, x - padding)\n    y = max(0, y - padding)\n    w = min(img.shape[1] - x, w + 2 * padding)\n    h = min(img.shape[0] - y, h + 2 * padding)\n    \n    # Crop the image\n    cropped_image = img[y:y+h, x:x+w]\n    \n    return cropped_image, (x, y, w, h)\n\ndef merge_nearby_masks(masks, distance_threshold=50):\n    \"\"\"Merge masks that are close to each other to capture complete products\"\"\"\n    \n    merged_masks = []\n    used_indices = set()\n    \n    for i, mask1 in enumerate(masks):\n        if i in used_indices:\n            continue\n            \n        # Get bounding box for current mask\n        mask1_array = mask1['segmentation']\n        contours1, _ = cv2.findContours((mask1_array > 0).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        \n        if len(contours1) == 0:\n            continue\n            \n        x1, y1, w1, h1 = cv2.boundingRect(max(contours1, key=cv2.contourArea))\n        center1 = (x1 + w1//2, y1 + h1//2)\n        \n        # Find nearby masks to merge\n        masks_to_merge = [mask1]\n        indices_to_merge = [i]\n        \n        for j, mask2 in enumerate(masks):\n            if j <= i or j in used_indices:\n                continue\n                \n            mask2_array = mask2['segmentation']\n            contours2, _ = cv2.findContours((mask2_array > 0).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            \n            if len(contours2) == 0:\n                continue\n                \n            x2, y2, w2, h2 = cv2.boundingRect(max(contours2, key=cv2.contourArea))\n            center2 = (x2 + w2//2, y2 + h2//2)\n            \n            # Calculate distance between centers\n            distance = np.sqrt((center1[0] - center2[0])**2 + (center1[1] - center2[1])**2)\n            \n            # Check if masks should be merged (close proximity and similar vertical position)\n            if distance < distance_threshold and abs(center1[1] - center2[1]) < h1//2:\n                masks_to_merge.append(mask2)\n                indices_to_merge.append(j)\n        \n        # Mark indices as used\n        used_indices.update(indices_to_merge)\n        \n        # Create merged mask\n        if len(masks_to_merge) > 1:\n            # Combine all masks\n            combined_mask = np.zeros_like(mask1['segmentation'])\n            total_area = 0\n            for mask in masks_to_merge:\n                combined_mask = np.logical_or(combined_mask, mask['segmentation'])\n                total_area += mask['area']\n            \n            merged_mask = {\n                'segmentation': combined_mask,\n                'area': total_area,\n                'bbox': cv2.boundingRect((combined_mask > 0).astype(np.uint8)),\n                'predicted_iou': np.mean([m['predicted_iou'] for m in masks_to_merge]),\n                'point_coords': masks_to_merge[0]['point_coords'],\n                'stability_score': np.mean([m['stability_score'] for m in masks_to_merge]),\n                'crop_box': masks_to_merge[0]['crop_box']\n            }\n            merged_masks.append(merged_mask)\n        else:\n            merged_masks.append(mask1)\n    \n    return merged_masks\n\ndef get_shelf_position(bbox, image_height, num_shelves=3):\n    \"\"\"Determine shelf position based on bounding box coordinates\"\"\"\n    x, y, w, h = bbox\n    center_y = y + h // 2\n    \n    # Define shelf regions based on image height\n    shelf_height = image_height // num_shelves\n    \n    if center_y < shelf_height:\n        shelf_level = \"top\"\n        shelf_number = 1\n    elif center_y < 2 * shelf_height:\n        shelf_level = \"middle\" \n        shelf_number = 2\n    else:\n        shelf_level = \"bottom\"\n        shelf_number = 3\n    \n    # Calculate relative position on shelf (left to right)\n    relative_position = x + w // 2  # center x coordinate\n    \n    return {\n        'shelf_level': shelf_level,\n        'shelf_number': shelf_number,\n        'x_position': x,\n        'y_position': y,\n        'center_x': x + w // 2,\n        'center_y': center_y,\n        'relative_position': relative_position\n    }"
  },
  {
   "cell_type": "markdown",
   "id": "719098bb-0748-487d-989a-230228a03cf1",
   "metadata": {
    "collapsed": false,
    "name": "cell15"
   },
   "source": [
    "## 2. Segment the Image and generate masks"
   ]
  },
  {
   "cell_type": "code",
   "id": "64f00373-cd4f-427e-83d6-2f8ddacd0499",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": "image = cv2.imread(SHELF_IMAGE_PATH)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec776674-5982-489e-91e9-a93f55f293a9",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "# Generate sub-image masks automatically\n\n################################################\n# SEGMENT ANYTHING 1.0\n################################################\nfrom segment_anything import sam_model_registry, SamAutomaticMaskGenerator\nsam_checkpoint = \"sam_vit_h_4b8939.pth\"\nmodel_type = \"vit_h\"\ndevice = \"cuda\"\n\nsam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\nsam.to(device=device)\n\n# Improved mask generator settings for better product segmentation\nmask_generator = SamAutomaticMaskGenerator(\n    model=sam,\n    points_per_side=32,  # More points for better coverage\n    pred_iou_thresh=0.9,  # Higher threshold for better quality masks\n    stability_score_thresh=0.98,  # Higher stability score\n    crop_n_layers=1,\n    crop_n_points_downscale_factor=2,\n    min_mask_region_area=1000,  # Filter out very small masks\n)\n\n# Generate initial masks\ninitial_masks = mask_generator.generate(image)\nprint(f\"Generated {len(initial_masks)} initial masks\")\n"
  },
  {
   "cell_type": "code",
   "id": "9fb5ac52-bf39-4457-a5ce-3eee4c08bfa5",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": "# Filter small masks that are likely image artifacts and merge masks that are close by together\n# TODO - Improve merging process\n# TODO - Improve small mask filtering to keep price tags\n\n# Filter masks by area to remove very small or very large masks (likely noise or background)\nfiltered_masks = [mask for mask in initial_masks if 1000 < mask['area'] < image.shape[0] * image.shape[1] * 0.3]\nprint(f\"After filtering: {len(filtered_masks)} masks\")\n\n# Merge nearby masks to capture complete products\nmasks = merge_nearby_masks(filtered_masks, distance_threshold=80)\nprint(f\"After merging: {len(masks)} final masks\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dd4e1281-36a5-43f8-83fb-6ca424f43622",
   "metadata": {
    "name": "cell22",
    "collapsed": false
   },
   "source": "## Review the different collections of Masks"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0272c087-ca1b-4630-8f0d-513e4155e3d2",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "# Review the Original Image\nplt.figure(figsize=(20,20))\nplt.imshow(image)\nplt.axis('off')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589f911-79a7-4f2d-9d3f-4b057b26fc66",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "# Review image with all masks\nplt.figure(figsize=(20,20))\nplt.imshow(image)\nshow_annotations(initial_masks)\nplt.axis('off')\nplt.show() "
  },
  {
   "cell_type": "code",
   "id": "69dfc6ca-0605-4287-a41b-f5b2333298c2",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": "# Review image with filtered & optimized masks\nplt.figure(figsize=(20,20))\nplt.imshow(image)\nshow_annotations(masks)\nplt.axis('off')\nplt.show() ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc950c2-194e-4a12-9fe2-c5db95cbd006",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "# Review one of the masked images with proper cropping\nif len(masks) > 1:\n    mymask = masks[37]['segmentation']\n    y=np.expand_dims(mymask,axis=2)\n    newmask=np.concatenate((y,y,y),axis=2)\n    masked_image = image * newmask\n    \n    # Use the improved cropping function\n    cropped_image, bbox = crop_image_to_relevant(masked_image, mymask)\n    \n    plt.figure(figsize=(15,10))\n    plt.subplot(1,2,1)\n    plt.imshow(masked_image)\n    plt.title('Original Masked Image')\n    plt.axis('off')\n    \n    plt.subplot(1,2,2)\n    plt.imshow(cropped_image)\n    plt.title('Cropped Image')\n    plt.axis('off')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    print(f\"Original dimensions: {masked_image.shape}\")\n    print(f\"Cropped dimensions: {cropped_image.shape}\")\n    print(f\"Bounding box: {bbox}\")\nelse:\n    print(\"No masks available for preview\") "
  },
  {
   "cell_type": "markdown",
   "id": "621e1040-4367-4e6b-93c0-745313ec26b7",
   "metadata": {
    "collapsed": false,
    "name": "cell10"
   },
   "source": [
    "## 3. Use Cortex multi-modal to extract information about the product\n",
    "Unfortunately Cortex Complete Multi-model is only supported in SQL for now, so for each masked image, we will first save them all to the local notebook folder and then we will call a PUT command to load them into a Snowflake stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb63ce0-bee4-4af0-951c-95d65e7fbc8c",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": [
    "# Save all masks as cropped files with position information\n",
    "import json\n",
    "\n",
    "counter = 0\n",
    "file_path = MASKED_IMAGES_OUTPUT_PATH\n",
    "mask_metadata = []  # Store metadata for each mask\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(file_path, exist_ok=True)\n",
    "\n",
    "for mask in masks:\n",
    "    mask_array = mask['segmentation']\n",
    "    y=np.expand_dims(mask_array,axis=2)\n",
    "    newmask=np.concatenate((y,y,y),axis=2)\n",
    "    \n",
    "    # Apply mask to original image\n",
    "    masked_image = image * newmask\n",
    "    \n",
    "    # Crop the image to remove black borders\n",
    "    try:\n",
    "        cropped_image, bbox = crop_image_to_relevant(masked_image, mask_array)\n",
    "        \n",
    "        # Get shelf position information\n",
    "        position_info = get_shelf_position(bbox, image.shape[0])\n",
    "        \n",
    "        # Save the cropped image\n",
    "        filename = f'product_{counter:03d}.jpg'\n",
    "        cv2.imwrite(file_path + filename, cv2.cvtColor(cropped_image, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        # Store metadata\n",
    "        metadata = {\n",
    "            'filename': filename,\n",
    "            'mask_id': counter,\n",
    "            'bbox': bbox,\n",
    "            'area': mask['area'],\n",
    "            'stability_score': mask['stability_score'],\n",
    "            'predicted_iou': mask['predicted_iou'],\n",
    "            **position_info\n",
    "        }\n",
    "        mask_metadata.append(metadata)\n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing mask {counter}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Save metadata to JSON file\n",
    "with open(file_path + 'mask_metadata.json', 'w') as f:\n",
    "    json.dump(mask_metadata, f, indent=2)\n",
    "\n",
    "print(f\"Saved {counter} cropped product images\")\n",
    "print(f\"Metadata saved to {file_path}mask_metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34cea3a-728a-48ef-9557-99ee5cc6a361",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    },
    "name": "cell16",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Create table to store product analysis results\nUSE DATABASE NOTEBOOK_DEMO_DB;\nUSE SCHEMA SHELF_IMAGE_AI;\nCREATE OR REPLACE TABLE product_analysis_results (\n    id INTEGER AUTOINCREMENT,\n    filename VARCHAR(255),\n    mask_id INTEGER,\n    shelf_level VARCHAR(50),\n    shelf_number INTEGER,\n    x_position INTEGER,\n    y_position INTEGER,\n    center_x INTEGER,\n    center_y INTEGER,\n    relative_position INTEGER,\n    bbox_x INTEGER,\n    bbox_y INTEGER,\n    bbox_width INTEGER,\n    bbox_height INTEGER,\n    mask_area INTEGER,\n    stability_score FLOAT,\n    predicted_iou FLOAT,\n    brand_name VARCHAR(255),\n    subbrand_name VARCHAR(255),\n    product_category VARCHAR(255),\n    size VARCHAR(255),\n    description_of_image TEXT,\n    cortex_response VARIANT,\n    processed_timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP(),\n    PRIMARY KEY (id)\n);\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e401d6-9b9d-4ad3-923d-ccd90e826fa8",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": true,
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": [
    "# Move all images to the stage\n",
    "images = os.listdir(MASKED_IMAGES_OUTPUT_PATH)\n",
    "\n",
    "for img in images:\n",
    "    put_result = session.file.put(\n",
    "        MASKED_IMAGES_OUTPUT_PATH + img,\n",
    "        IMAGE_STAGE_LOCATION,\n",
    "        auto_compress=False,  # Optional: Compress the file during upload (default is True)\n",
    "        overwrite=True       # Optional: Overwrite if a file with the same name exists (default is False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f4560-1557-483d-bd42-fd8ed7bbfe83",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "# Batch process all images with Cortex Complete and store results in Snowflake\n\n# Load the metadata we saved earlier\nwith open(file_path + 'mask_metadata.json', 'r') as f:\n    metadata_list = json.load(f)\n\n# Get list of all image files in the stage\nstage_files_query = f\"LIST {IMAGE_STAGE_LOCATION}\"\nstage_files_result = session.sql(stage_files_query).collect()\n\n# Extract just the filenames from the stage listing\nstage_files = [row[0].split('/')[-1] for row in stage_files_result if row[0].endswith('.jpg') and 'product_' in row[0]]\n\nprint(f\"Found {len(stage_files)} product images in stage\")\nprint(f\"Metadata available for {len(metadata_list)} products\")\n\n# Process each image with Cortex Complete\nsuccessful_inserts = 0\nfailed_inserts = 0\n\nfor metadata in metadata_list:\n    filename = metadata['filename']\n    \n    # Check if file exists in stage\n    if filename not in stage_files:\n        print(f\"Warning: {filename} not found in stage, skipping...\")\n        failed_inserts += 1\n        continue\n    \n    try:\n        # Cortex Complete query for this specific image\n        cortex_query = f\"\"\"\n        SELECT snowflake.cortex.complete('pixtral-large', \n            'Analyze this product image from a retail shelf. The image has been cropped to focus on a single product.\n            Provide detailed information about the product you see.\n            If the product is not clearly visible or appears to be incomplete/damaged, respond with N/A for unclear fields.\n            Respond ONLY with valid JSON containing these exact fields and DO NOT surround the json with markdown:\n            {{\n                \"brand_name\": \"brand name of the product\",\n                \"subbrand_name\": \"sub-brand or product line name if visible\", \n                \"product_category\": \"category like beverages, snacks, dairy, etc\",\n                \"size\": \"package size or volume if visible\",\n                \"description_of_image\": \"brief description of what you see in the image\"\n            }}',\n            TO_FILE('{IMAGE_STAGE_LOCATION}', '{filename}')\n        ) as cortex_response\n        \"\"\"\n        \n        # Execute Cortex Complete query\n        cortex_result = session.sql(cortex_query).collect()\n        cortex_response = cortex_result[0]['CORTEX_RESPONSE']\n        \n        # Try to parse the JSON response\n        try:\n            parsed_response = json.loads(cortex_response)\n            brand_name = parsed_response.get('brand_name', 'N/A')\n            subbrand_name = parsed_response.get('subbrand_name', 'N/A') \n            product_category = parsed_response.get('product_category', 'N/A')\n            size = parsed_response.get('size', 'N/A')\n            description = parsed_response.get('description_of_image', 'N/A')\n        except json.JSONDecodeError:\n            print(f\"Warning: Could not parse JSON response for {filename}\")\n            brand_name = subbrand_name = product_category = size = description = 'N/A'\n        \n        # Insert into the results table\n        insert_query = f\"\"\"\n        INSERT INTO product_analysis_results (\n            filename, mask_id, shelf_level, shelf_number, x_position, y_position,\n            center_x, center_y, relative_position, bbox_x, bbox_y, bbox_width, bbox_height,\n            mask_area, stability_score, predicted_iou, brand_name, subbrand_name,\n            product_category, size, description_of_image, cortex_response\n        ) VALUES (\n            '{filename}', {metadata['mask_id']}, '{metadata['shelf_level']}', \n            {metadata['shelf_number']}, {metadata['x_position']}, {metadata['y_position']},\n            {metadata['center_x']}, {metadata['center_y']}, {metadata['relative_position']},\n            {metadata['bbox'][0]}, {metadata['bbox'][1]}, {metadata['bbox'][2]}, {metadata['bbox'][3]},\n            {metadata['area']}, {metadata['stability_score']}, {metadata['predicted_iou']},\n            '{brand_name}', '{subbrand_name}', '{product_category}', '{size}', \n            '{description}', PARSE_JSON('{cortex_response.replace(\"'\", \"''\")}')\n        )\n        \"\"\"\n        \n        session.sql(insert_query).collect()\n        successful_inserts += 1\n        print(f\"✓ Processed {filename} - {brand_name} ({product_category})\")\n        \n    except Exception as e:\n        print(f\"✗ Error processing {filename}: {str(e)}\")\n        failed_inserts += 1\n        continue\n\nprint(f\"\\nBatch processing complete!\")\nprint(f\"Successfully processed: {successful_inserts}\")\nprint(f\"Failed: {failed_inserts}\")\nprint(f\"Total: {len(metadata_list)}\")\n\n# Display summary of results\nsummary_query = \"\"\"\nSELECT \n    shelf_level,\n    COUNT(*) as product_count,\n    COUNT(DISTINCT brand_name) as unique_brands,\n    COUNT(DISTINCT product_category) as unique_categories\nFROM product_analysis_results \nWHERE brand_name != 'N/A'\nGROUP BY shelf_level\nORDER BY shelf_number\n\"\"\"\n\nprint(\"\\n--- Shelf Analysis Summary ---\")\nsummary_results = session.sql(summary_query).collect()\nfor row in summary_results:\n    print(f\"{row['SHELF_LEVEL'].title()} Shelf: {row['PRODUCT_COUNT']} products, {row['UNIQUE_BRANDS']} brands, {row['UNIQUE_CATEGORIES']} categories\")"
  },
  {
   "cell_type": "code",
   "id": "37846381-dfc1-495d-a128-e0d8e89b0e00",
   "metadata": {
    "language": "python",
    "name": "cell19"
   },
   "outputs": [],
   "source": "with open(file_path + 'mask_metadata.json', 'r') as f:\n    metadata_list = json.load(f)\n\nmetadata_list",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f03b61-67ba-43fa-a7d6-b604a70d49f1",
   "metadata": {
    "name": "cell17",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Additional analysis queries and visualizations\n",
    "\n",
    "# Query 1: Products by shelf position (left to right)\n",
    "position_query = \"\"\"\n",
    "SELECT \n",
    "    shelf_level,\n",
    "    filename,\n",
    "    brand_name,\n",
    "    product_category,\n",
    "    relative_position,\n",
    "    center_x,\n",
    "    center_y\n",
    "FROM product_analysis_results \n",
    "WHERE brand_name != 'N/A'\n",
    "ORDER BY shelf_number, relative_position\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Products by Shelf Position (Left to Right) ---\")\n",
    "position_results = session.sql(position_query).collect()\n",
    "current_shelf = None\n",
    "for row in position_results:\n",
    "    if current_shelf != row['SHELF_LEVEL']:\n",
    "        current_shelf = row['SHELF_LEVEL']\n",
    "        print(f\"\\n{current_shelf.title()} Shelf:\")\n",
    "    print(f\"  {row['BRAND_NAME']} - {row['PRODUCT_CATEGORY']} (x: {row['CENTER_X']})\")\n",
    "\n",
    "# Query 2: Brand distribution across shelves\n",
    "brand_distribution_query = \"\"\"\n",
    "SELECT \n",
    "    brand_name,\n",
    "    shelf_level,\n",
    "    COUNT(*) as product_count,\n",
    "    AVG(relative_position) as avg_position\n",
    "FROM product_analysis_results \n",
    "WHERE brand_name != 'N/A'\n",
    "GROUP BY brand_name, shelf_level\n",
    "ORDER BY brand_name, shelf_number\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Brand Distribution Across Shelves ---\")\n",
    "brand_results = session.sql(brand_distribution_query).collect()\n",
    "for row in brand_results:\n",
    "    print(f\"{row['BRAND_NAME']} on {row['SHELF_LEVEL']} shelf: {row['PRODUCT_COUNT']} products (avg position: {row['AVG_POSITION']:.0f})\")\n",
    "\n",
    "# Query 3: Create a simple shelf map visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get all products with positions\n",
    "map_query = \"\"\"\n",
    "SELECT \n",
    "    center_x, center_y, brand_name, product_category, shelf_level\n",
    "FROM product_analysis_results \n",
    "WHERE brand_name != 'N/A'\n",
    "\"\"\"\n",
    "\n",
    "map_results = session.sql(map_query).collect()\n",
    "\n",
    "if map_results:\n",
    "    # Create shelf map visualization\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Color map for different categories\n",
    "    categories = list(set([row['PRODUCT_CATEGORY'] for row in map_results]))\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(categories)))\n",
    "    category_colors = dict(zip(categories, colors))\n",
    "    \n",
    "    for row in map_results:\n",
    "        x = row['CENTER_X']\n",
    "        y = row['CENTER_Y'] \n",
    "        category = row['PRODUCT_CATEGORY']\n",
    "        brand = row['BRAND_NAME']\n",
    "        \n",
    "        ax.scatter(x, y, c=[category_colors[category]], s=100, alpha=0.7)\n",
    "        ax.annotate(f\"{brand}\\n{category}\", (x, y), xytext=(5, 5), \n",
    "                   textcoords='offset points', fontsize=8, ha='left')\n",
    "    \n",
    "    ax.set_xlabel('Horizontal Position (pixels)')\n",
    "    ax.set_ylabel('Vertical Position (pixels)')\n",
    "    ax.set_title('Shelf Product Map')\n",
    "    ax.invert_yaxis()  # Invert Y axis so top of image is at top\n",
    "    \n",
    "    # Add legend\n",
    "    legend_elements = [plt.scatter([], [], c=[category_colors[cat]], s=100, label=cat) \n",
    "                      for cat in categories]\n",
    "    ax.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Query 4: Export final results for external analysis\n",
    "export_query = \"\"\"\n",
    "SELECT * FROM product_analysis_results \n",
    "WHERE brand_name != 'N/A'\n",
    "ORDER BY shelf_number, relative_position\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\n--- Final Results Summary ---\")\n",
    "final_results = session.sql(export_query).collect()\n",
    "print(f\"Total products successfully analyzed: {len(final_results)}\")\n",
    "\n",
    "# Show sample results\n",
    "print(\"\\nSample results:\")\n",
    "for i, row in enumerate(final_results[:5]):\n",
    "    print(f\"{i+1}. {row['BRAND_NAME']} - {row['PRODUCT_CATEGORY']} on {row['SHELF_LEVEL']} shelf\")\n",
    "\n",
    "print(f\"\\nAll results are stored in the 'product_analysis_results' table in Snowflake.\")\n"
   ]
  }
 ]
}